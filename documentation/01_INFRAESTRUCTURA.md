# üèóÔ∏è 01. Infraestructura y Arquitectura General

> **Visi√≥n Global**: C√≥mo dise√±amos un sistema de IA Enterprise para correr en una "patata" (2GB RAM / 1 CPU).
> **Objetivo**: Eficiencia Extrema, Latencia M√≠nima y Seguridad Zero-Trust.

---

## 1. El Desaf√≠o: "Constraints-First Design"
La mayor√≠a de SaaS de IA queman dinero en servidores GPU masivos. AgentShield hace lo contrario.
*   **Hardware Objetivo**: Render Free/Starter Tier (o AWS t4g.small).
*   **Recursos**: 512MB - 2GB RAM, 0.5 - 1 CPU Core.
*   **Requisito Latencia**: < 200ms overhead sobre la llamada a OpenAI.

Para lograr esto, no pudimos usar frameworks pesados (Django, Celery). Tuvimos que ingenier√≠a h√≠brida.

### La Soluci√≥n H√≠brida (Python + Rust)
No es 100% Python. Las partes cr√≠ticas corren en c√≥digo nativo compilado.

| Componente | Tecnolog√≠a | Por qu√© |
| :--- | :--- | :--- |
| **Servidor Web** | `Granian` (Rust) | Maneja HTTP/2 y WebSockets con un loop m√°s eficiente que Uvicorn. |
| **L√≥gica Negocio** | `FastAPI` (Python) | Velocidad de desarrollo y ecosistema de IA. |
| **PII Scrubbing** | `Rust Regex` | Escanear 1MB de texto en Python bloquea la CPU 50ms. En Rust, 0.5ms. |
| **Caching** | `Redis` (Memory) | Persistencia vol√°til ultrarr√°pida (Cache, Rate Limit). |
| **Persistencia** | `Supabase` (SaaS) | Delegamos la DB pesada (PostgreSQL) para no gastar CPU local. |

---

## 2. Arquitectura de Despliegue

```mermaid
graph TD
    User[Cliente SaaS] -->|HTTPS| CF[Cloudflare WAF]
    CF -->|Zero-Trust Header| Server[AgentShield (Render/K8s)]
    
    subgraph "AgentShield Pod (2GB RAM)"
        Server -->|Auth Check| Redis[(Redis Cache)]
        Server -->|PII Scan| RustCore[Rust Module]
        Server -->|Router| Proxy[Universal Proxy]
    end
    
    Proxy -->|Cache Hit?| Redis
    Proxy -->|No Hit| Arbitraje[RL Arbitrage Engine]
    Arbitraje -->|Selecci√≥n| LiteLLM[LiteLLM Gateway]
    
    LiteLLM -->|API Call| OpenAI[OpenAI / Anthropic]
    LiteLLM -->|API Call| Local[Ollama / LocalAI]
```

---

## 3. Estructura de Documentaci√≥n Detallada
Para entender cada tornillo, revisa los "Deep Dives":

*   **[01.1 Dockerfile y Build](01.1_INFRA_DOCKER.md)**: C√≥mo logramos im√°genes de 150MB con modelos pre-cargados.
*   **[01.2 N√∫cleo Rust](01.2_INFRA_RUST.md)**: Explicaci√≥n del c√≥digo `lib.rs` y la integraci√≥n PyO3.
*   **[01.3 Dependencias](01.3_INFRA_DEPENDENCIAS.md)**: Por qu√© elegimos cada librer√≠a en `requirements.txt`.

---

## 4. Filosof√≠a "Stateless"
El servidor no guarda estado en memoria entre peticiones (excepto modelos cargados en Read-Only).
*   **Si se reinicia el servidor**: No se pierde nada (todo est√° en Redis/Supabase).
*   **Escalado**: Puedes levantar 50 r√©plicas del contenedor y todas compartir√°n el conocimiento (Limitador de Velocidad global, Cach√© global).

---

## 5. Secret Management (Vault Virtual)
No guardamos claves API en la DB.
*   Las claves maestras (OpenAI, Anthropic) se inyectan como Variables de Entorno en el despliegue.
*   El c√≥digo usa `app.services.vault.get_secret()` para recuperarlas en tiempo de ejecuci√≥n de forma segura.
