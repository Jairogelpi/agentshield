# agentshield_core/app/routers/proxy.py
import os
import os
from app.utils import fast_json as json # RUST ACCELERATED JSON
import asyncio
import time
import logging
import io
import base64
import hmac
import hashlib
from datetime import datetime
from fastapi import APIRouter, Request, Header, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse, JSONResponse, Response
from litellm import acompletion, embedding, image_generation
from PIL import Image
import piexif
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.asymmetric import padding
from cryptography.hazmat.primitives import serialization

logger = logging.getLogger("agentshield.proxy")

# --- RUST ACCELERATOR (HYBRID MODE) ---
try:
    import agentshield_rust
    RUST_AVAILABLE = True
    logger.info("üöÄ Rust Accelerator Loaded: C2PA Signing is running on bare metal.")
except ImportError:
    RUST_AVAILABLE = False
    logger.warning("üê¢ Rust Accelerator Not Found: Falling back to slow Python signing.")

# Imports propios
from app.routers.authorize import get_tenant_from_header
from app.services.billing import record_transaction, settle_knowledge_exchange, check_budget_integrity
from app.estimator import estimator
from app.db import redis_client, supabase
from app.limiter import limiter
from app.logic import verify_residency, get_active_policy
from app.services.cache import get_semantic_cache_full_data, set_semantic_cache, get_sovereign_market_hit
from app.services.reranker import verify_cache_logic
from app.services.vault import get_secret
from app.services.pii_guard import advanced_redact_pii
from app.services.carbon import calculate_footprint
from app.models import SovereignConfig
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode
from app.services.arbitrage import arbitrage_engine


tracer = trace.get_tracer(__name__)
CURRENT_REGION = os.getenv("SERVER_REGION", "eu")

# ... (omitted C2PA and helper functions unchanged) ...

# ==========================================
# 1. TEXT / CHAT ENDPOINT (Con Honeypot & Sovereign Market)
# ==========================================
@router.post("/v1/chat/completions")
@limiter.limit("600/minute")
async def chat_proxy(request: Request, background_tasks: BackgroundTasks, authorization: str = Header(...)):
    with tracer.start_as_current_span("chat_proxy") as span:
        trace_id = format(span.get_span_context().trace_id, '032x')
        start_time = time.time()
        client_ip = request.headers.get("cf-connecting-ip", request.client.host)

        # 0. BLACKLIST CHECK (Zero-Cost Firewall)
        if await redis_client.get(f"blacklist:{client_ip}"):
             logger.warning(f"‚õî Blacklisted IP blocked: {client_ip}")
             raise HTTPException(status_code=403, detail="Access Denied by Security Policy")

        # Auth & Setup
        try:
            as_key = authorization.replace("Bearer ", "").strip()
            # PARALLEL AUTH CHECKS (Reduce latency by performing IO concurrently)
            # 1. Tenant ID is needed first
            tenant_id = await get_tenant_from_header(x_api_key=as_key)
            
            # 2. Run independent checks in parallel
            # verify_residency, get_proxy_cost_center, get_active_policy can run together
            results = await asyncio.gather(
                verify_residency(tenant_id),
                get_proxy_cost_center(tenant_id),
                get_active_policy(tenant_id)
            )
            # Unpack results (verify_residency returns check result, others return data)
            _, cost_center_id, policy = results
            
            tenant_allowlist = policy.get("allowlist", {}).get("models", [])
            # Parse Sovereign Config
            sov_conf_dict = policy.get("sovereign_config", {})
            sov_config = SovereignConfig(**sov_conf_dict) if sov_conf_dict else SovereignConfig()
            
        except Exception as e: raise HTTPException(status_code=401, detail="Auth Failed")

        body = await request.json()
        model = body.get("model")
        messages = body.get("messages", [])
        stream = body.get("stream", False)
        # Extraemos max_tokens para evitar errores en respuestas largas
        user_max_tokens = body.get("max_tokens") or body.get("max_completion_tokens")
        
        # --- 0. BUDGET & SECURITY CHECK (Real-Time) ---
        # Estimamos coste PEOR CASO antes de nada
        # Asumimos que user_max_tokens ser√° usado a tope si no se especifica.
        # Si no especifica, asumimos 500 (safe default) para el check, pero luego inyectamos l√≠mite.
        check_tokens = int(user_max_tokens or 1000) + len(str(messages))
        est_cost_check = estimator.estimate_cost(model, "COMPLETION", input_unit_count=check_tokens)
        
        # Check Integrity & Kill Switch
        can_spend, reason = await check_budget_integrity(tenant_id, est_cost_check)
        if not can_spend:
             if reason == "KILL_SWITCH_TRIGGERED":
                 raise HTTPException(429, "Security Alert: Spending Velocity Exceeded. Account Frozen.")
             raise HTTPException(402, "Payment Required: Budget Exceeded")

        # --- DYNAMIC MAX_TOKENS INJECTION (Anti-Drain) ---
        # Calculamos cu√°ntos tokens le quedan de vida al tenant
        # Limit - Current = Remaining $
        # Remaining $ / CostPerToken = Safe Max Output
        # (Simplificado: Traemos el budget remaining dentro de la funcion de integritad o hacemos otra llamada)
        # Para no duplicar llamadas a Redis, asumimos que si pas√≥ el check, tiene saldo.
        # Pero para ser "State of the Art", calc√∫lemoslo.
        
        # Recuperamos saldo restante (podr√≠amos optimizar devolvi√©ndolo en check_budget_integrity)
        # Vamos a hacer una estimaci√≥n r√°pida:
        # Si est_cost_check era OK, user_max_tokens es seguro.
        # Pero si user_max_tokens era None, debemos poner un techo.
        
        if not user_max_tokens:
             # Inyectamos topes seguros para evitar loops infinitos
             max_tokens = 2000 # Default sensato
        else:
             max_tokens = int(user_max_tokens)
             
        # Actualizamos body
        body['max_tokens'] = max_tokens

        # PII Scrubbing
        clean_msgs = []
        for m in messages:
            clean_msgs.append({"role": m["role"], "content": await advanced_redact_pii(m.get("content",""), tenant_id)})

        # --- 1. SOVEREIGN MEMORY BANK (The "Marketplace") ---
        # Prioridad: Comprar conocimiento antes que computar
        if clean_msgs and sov_config.buy_knowledge:
            prompt = clean_msgs[-1]["content"]
            
            # A. Check Local Cache (Free)
            local_cache = await get_semantic_cache_full_data(prompt)
            if local_cache and await verify_cache_logic(prompt, local_cache['prompt']):
                 background_tasks.add_task(record_transaction, tenant_id, cost_center_id, 0.0, {"trace_id": trace_id, "cache": "HIT_LOCAL"})
                 return {"choices": [{"message": {"content": local_cache['response']}, "finish_reason": "stop"}], "model": model}
            
            # B. Check Sovereign Market (Paid but Discounted)
            market_hit = await get_sovereign_market_hit(prompt, tenant_id)
            if market_hit:
                 # Verificaci√≥n de Calidad (Reranker) - ¬°CRUCIAL ANTES DE PAGAR!
                 if await verify_cache_logic(prompt, market_hit['prompt']):
                     # Verificaci√≥n de PII (Cleanse Seller Data) - !CRUCIAL PARA PRIVACIDAD!
                     safe_response = await advanced_redact_pii(market_hit['response'], tenant_id)
                     
                     # Transacci√≥n Financiera
                     estimated_full_cost = estimator.estimate_cost(model, "COMPLETION", input_unit_count=(len(prompt) + len(safe_response))//4)
                     final_price = await settle_knowledge_exchange(tenant_id, market_hit['owner_id'], estimated_full_cost)
                     
                     logger.info(f"üí∞ Sovereign Deal: {tenant_id} bought from {market_hit['owner_id']} for {final_price}‚Ç¨")
                     
                     background_tasks.add_task(record_transaction, tenant_id, cost_center_id, final_price, {
                         "trace_id": trace_id, 
                         "cache": "HIT_MARKET", 
                         "seller": market_hit['owner_id'],
                         "quality_score": market_hit.get('rerank_score', 1.0) # Evidence of Quality
                     })
                     return {"choices": [{"message": {"content": safe_response}, "finish_reason": "stop"}], "model": model}


        # --- üí∞ ARBITRAJE SEM√ÅNTICO UNIVERSAL (FOMO EDITION) ---
        complexity_analysis = await arbitrage_engine.analyze_complexity(clean_msgs)
        complexity_score = complexity_analysis.get("score", 100)
        
        # Verificar Configuraci√≥n del Tenant (Sovereign Control)
        is_smart_routing_enabled = sov_config.smart_routing_enabled
        
        # 1. Calcular Ganancia Potencial (Siempre, para m√©tricas)
        potential_saving_per_token, potential_cheaper_model = await arbitrage_engine.get_potential_arbitrage_gain(
            model, complexity_score
        )
        
        final_model = model
        
        if is_smart_routing_enabled:
            # Flujo Normal: Intentar optimizar
            final_model, arbitrage_status, savings_pct = await arbitrage_engine.find_best_bidder(
                model, 
                complexity_analysis,
                max_output_tokens=int(max_tokens),
                tenant_allowlist=tenant_allowlist
            )
            if final_model != model:
                logger.info(f"‚ö° SMART ROUTING: {model} -> {final_model} (Score: {complexity_score})")
                span.set_attribute("arbitrage.original", model)
                span.set_attribute("arbitrage.final", final_model)
                span.set_attribute("arbitrage.Complexity", complexity_score)
        else:
            # Flujo FOMO: Si est√° APAGADO pero hab√≠a oportunidad
            if potential_saving_per_token > 0:
                from app.services.carbon import calculate_extra_emission
                
                logger.info(f"üí∏ MISSED SAVING: Could have used {potential_cheaper_model}")
                span.set_attribute("arbitrage.skipped_by_config", True)
                
                # Calcular impacto financiero y ambiental
                # Estimar tokens totales (input + max_output como peor caso para la alerta)
                est_total_tokens = complexity_analysis.get("input_tokens", 0) + int(max_tokens)
                
                missed_money = await estimator.calculate_projected_loss(model, potential_cheaper_model, est_total_tokens)
                missed_carbon = calculate_extra_emission(model, potential_cheaper_model)
                
                span.set_attribute("economy.missed_saving", float(missed_money))
                span.set_attribute("sustainability.missed_carbon_saving", float(missed_carbon))
                
                # Persistir m√©tricas de "Dolor" (Atomic Increment)
                p = redis_client.pipeline()
                p.incrbyfloat(f"stats:{tenant_id}:missed_savings", missed_money)
                p.incrbyfloat(f"stats:{tenant_id}:missed_carbon", missed_carbon)
                await p.execute()
        
        model = final_model

        # Guard & Execution
        provider = model.split("/")[0].upper() if "/" in model else "OPENAI"
        api_key = get_secret(f"LLM_KEY_{provider}")
        
        guard_task = asyncio.create_task(detect_risk_with_llama_guard(clean_msgs))
        llm_task = asyncio.create_task(acompletion(model=model, messages=clean_msgs, stream=stream, api_key=api_key, **{k:v for k,v in body.items() if k not in ["model","messages","stream"]}))

        try:
            if await asyncio.wait_for(asyncio.shield(guard_task), timeout=0.5): # Unsafe?
                llm_task.cancel()
                if stream: raise HTTPException(403, "Blocked")
                return await execute_honeypot_trap(clean_msgs, model, trace_id, tenant_id, client_ip)
        except asyncio.TimeoutError:
            llm_task.cancel()
            raise HTTPException(403, "Security Timeout")

        # INICIO CRON√ìMETRO DE LATENCIA (SLA Monitoring)
        req_start = time.time() 

        try:
            response = await llm_task
        except Exception as e:
            # Si falla, penalizamos el modelo con latencia alta para evitarlo temporalmente
            background_tasks.add_task(arbitrage_engine.record_latency, final_model, 5000.0)
            raise e
            
        # FIN CRON√ìMETRO
        req_end = time.time()
        actual_latency = (req_end - req_start) * 1000 # a milisegundos
        
        # üß† ALIMENTAR EL CEREBRO: Registramos la latencia real para futuros arbitrajes
        background_tasks.add_task(arbitrage_engine.record_latency, final_model, actual_latency)

        # Response Handling
        if stream:
            async def generator(resp):
                full = ""
                async for chunk in resp:
                    c = chunk.choices[0].delta.content or ""
                    full += c
                    yield f"data: {json.dumps(chunk.json())}\n\n"
                yield "data: [DONE]\n\n"
                cost = estimator.estimate_cost(model, "COMPLETION", input_unit_count=len(full)//4) # Aprox
                await record_transaction(tenant_id, cost_center_id, cost, {"model": model, "mode": "stream"})
            return StreamingResponse(generator(response), media_type="text/event-stream")
        else:
            final_text = await advanced_redact_pii(response.choices[0].message.content, tenant_id)
            response.choices[0].message.content = final_text
            
            # Caching & Logging (Including Sovereign Ownership)
            if clean_msgs: 
                 background_tasks.add_task(
                     set_semantic_cache, 
                     clean_msgs[-1]["content"], 
                     final_text, 
                     tenant_id, # Owner
                     sov_config # Config rules
                 )
            
            est_cost = estimator.estimate_cost(model, "COMPLETION", input_unit_count=(len(str(clean_msgs)) + len(final_text))//4)
            carbon = calculate_footprint(model, CURRENT_REGION, 100) # Placeholder size
            
            background_tasks.add_task(record_transaction, tenant_id, cost_center_id, est_cost, {"model": model, "trace_id": trace_id, "carbon": carbon})
            background_tasks.add_task(run_flight_recorder, trace_id, tenant_id, clean_msgs[-1]["content"], final_text)
            
            # --- üöÄ DEEP RL FEEDBACK LOOP (2026 Core) ---
            # El agente aprende de la realidad: ¬øFue buena la decisi√≥n?
            if 'rl_state' in complexity_analysis:
                async def _feedback_worker(trace_id, prompt, response, latency, savings, state, model_used):
                    with tracer.start_as_current_span("rl_feedback_loop") as span:
                         try:
                             # 1. Medir Calidad Real (Reranker) - Self-Correction
                             # Usamos verify_cache_logic para obtener el score sem√°ntico entre prompt y output
                             # (Aunque verify_cache_logic compara prompt-prompt, aqu√≠ usamos el Reranker para QA o similar
                             # pero para simplificar m√©trica de "precisi√≥n", asumimos que un score alto de reranker entre
                             # pregunta y respuesta denota coherencia, o usamos un modelo dedicado.
                             # El usuario pidi√≥: "quality_score = await reranker.get_score(user_prompt, llm_response)"
                             # Sin embargo, reranker.py tiene verify_cache_logic. Vamos a asumir que usamos esa misma logica
                             # o a√±adimos un metodo get_score si verify_cache_logic es muy especifico.
                             # De hecho, verify_cache_logic usa 'verify_cache_logic(q, cached)'.
                             # Vamos a usar verify_cache_logic(clean_msgs[-1]["content"], final_text) como proxy de "relevancia"
                             # aunque esto no es exacto para QA.
                             # MEJOR: Usar el modelo dummy o el reranker como "Score de Coherencia"
                             # O REVISAR RERANKER: El CrossEncoder puede predecir (q, a) relevance score.
                             
                             from app.services.reranker import verify_cache_logic
                             
                             # Como verify_cache_logic devuelve (bool, score), usamos el score.
                             # Nota: verify_cache_logic compara 2 PREGUNTAS. Aqu√≠ queremos Q vs A.
                             # El CrossEncoder 'ms-marco' est√° entrenado para (Query, Passage). Funciona perfecto.
                             _, quality_score = await verify_cache_logic(prompt, response)
                             
                             # 2. Calcular Recompensa
                             reward = arbitrage_engine.calculate_reward(
                                 cost_saved=savings, # Ya calculamos savings antes
                                 rerank_score=quality_score,
                                 latency_ms=latency
                             )
                             
                             # 3. Actualizar Cerebro (Redis Q-Table)
                             await arbitrage_engine.update_learning(state, model_used, reward)
                             
                             span.set_attribute("rl.reward_generated", float(reward))
                             span.set_attribute("rl.quality_score", float(quality_score))
                             span.set_attribute("rl.state", state)
                         except Exception as e:
                             logger.error(f"RL Feedback Error: {e}")

                # Lanzamos el aprendizaje en background para no latencia
                background_tasks.add_task(
                    _feedback_worker, 
                    trace_id, 
                    clean_msgs[-1]["content"], 
                    final_text, 
                    actual_latency, 
                    savings_pct, # Este ven√≠a de find_best_bidder
                    complexity_analysis['rl_state'],
                    final_model
                )

            return JSONResponse(content=json.loads(response.json()))

# ==========================================
# 2. IMAGE GENERATION ENDPOINT (Con C2PA)
# ==========================================
@router.post("/v1/images/generations")
@limiter.limit("50/minute")
async def image_proxy(request: Request, background_tasks: BackgroundTasks, authorization: str = Header(...)):
    with tracer.start_as_current_span("image_proxy") as span:
        trace_id = format(span.get_span_context().trace_id, '032x')
        
        # Auth
        try:
            as_key = authorization.replace("Bearer ", "").strip()
            tenant_id = await get_tenant_from_header(x_api_key=as_key)
            cost_center_id = await get_proxy_cost_center(tenant_id)
        except: raise HTTPException(401, "Auth Failed")

        body = await request.json()
        model = body.get("model", "dall-e-3")
        prompt = body.get("prompt", "")
        size = body.get("size", "1024x1024")

        # PII en Prompt
        safe_prompt = await advanced_redact_pii(prompt, tenant_id)

        # Provider Key
        provider = "OPENAI" # Default para im√°genes por ahora
        api_key = get_secret(f"LLM_KEY_{provider}")

        try:
            # 1. Generar Imagen (Pedimos b64_json para poder firmarla sin bajarla de una URL externa)
            # Forzamos response_format='b64_json' para inyectar metadatos
            response = await image_generation(
                model=model,
                prompt=safe_prompt,
                size=size,
                api_key=api_key,
                response_format="b64_json",
                n=1
            )
            
            # 2. Procesar y Firmar (C2PA) - PARALLEL EXECUTION
            loop = asyncio.get_running_loop()
            
            async def process_image(item):
                raw_img_bytes = base64.b64decode(item.b64_json)
                signed_img_bytes = await loop.run_in_executor(
                    None, 
                    sign_image_content, 
                    raw_img_bytes, tenant_id, trace_id, model
                )
                signed_b64 = base64.b64encode(signed_img_bytes).decode('utf-8')
                return {"b64_json": signed_b64, "revised_prompt": item.revised_prompt}

            # Gather all signing tasks
            signed_data = await asyncio.gather(*(process_image(item) for item in response.data))

            # 3. Calcular Costes
            cost = estimator.estimate_cost(model, "IMAGE_GENERATION", resolution=size)
            carbon = calculate_footprint(model, CURRENT_REGION, 1000) # Imagen es pesado

            background_tasks.add_task(
                record_transaction, 
                tenant_id, cost_center_id, cost, 
                {"model": model, "mode": "image", "trace_id": trace_id, "carbon": carbon, "provenance": "C2PA_SIGNED"}
            )

            # Devolvemos estructura est√°ndar OpenAI
            return {
                "created": int(time.time()),
                "data": signed_data
            }

        except Exception as e:
            logger.error(f"Image Gen Error: {e}")
            raise HTTPException(status_code=500, detail=str(e))
